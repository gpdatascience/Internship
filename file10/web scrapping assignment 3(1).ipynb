{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb45f54",
   "metadata": {},
   "source": [
    "Q-1 Write a python program which searches all the product under a particular product from www.amazon.in. The\n",
    "product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for\n",
    "guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b55196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f9fa406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activating the browser\n",
    "driver = webdriver.Chrome()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1e76b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Open the search URL\n",
    "driver.get(\"https://www.amazon.in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "332c012c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product you want to search on https://www.amazon.in: guitar\n"
     ]
    }
   ],
   "source": [
    "product_name = input(\"Enter the product you want to search on https://www.amazon.in: \")\n",
    "search_box=driver.find_element(By.XPATH,\"//*[@id='twotabsearchtextbox'] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c2d0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35eb2290",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box.send_keys(product_name)\n",
    "search_button = driver.find_element(By.XPATH,\"//input[@type='submit']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54f2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sleep(10)\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5850e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-2 In the above question, now scrape the following details of each product listed in first 3 pages of your search\n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then\n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0257398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List for different attributes-\n",
    "\n",
    "name_of_the_Product=[]\n",
    "price=[]\n",
    "return_Exchange=[]\n",
    "expected_Delivery=[]\n",
    "availability=[]\n",
    "#Product_URL=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebac65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Data for different Attributes-\n",
    "#brand_tags = driver.find_elements(By.XPATH,'//*[@id=\"search\"]/div[1]/div[1]/div/span[1]/div[1]/div[3]/div/div/div/div/div/div/div[2]/div[1]/h2/a/span')\n",
    "#for i in brand_tags[0:10]:\n",
    "    #brand=i.text\n",
    "    #brand_Name.append(brand)\n",
    "\n",
    "\n",
    "name_tags = driver.find_elements(By.XPATH,'//*[@id=\"search\"]/div[1]/div[1]/div/span[1]/div[1]/div[3]/div/div/div/div/div/div/div[2]/div[1]/h2/a/span')\n",
    "for i in name_tags[0:10]:\n",
    "    name=i.text\n",
    "    name_of_the_Product.append(name)\n",
    "    \n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH,'//*[@id=\"search\"]/div[1]/div[1]/div/span[1]/div[1]/div[3]/div/div/div/div/div/div/div[2]/div[3]/div[2]/a/span/span[2]/span[2]')  \n",
    "for i in price_tags[0:10]:\n",
    "    pr=i.text\n",
    "    price.append(pr)   \n",
    "    \n",
    "    \n",
    "return_Exchange_tags = driver.find_elements(By.XPATH,'//*[@id=\"RETURNS_POLICY\"]/span/div[2]/span')  \n",
    "for i in return_Exchange_tags[0:10]:\n",
    "    ret_ex=i.text\n",
    "    return_Exchange.append(ret_ex)\n",
    "\n",
    "expected_Delivery_tags = driver.find_elements(By.CLASS_NAME,'a-text-bold')  \n",
    "for i in expected_Delivery_tags[0:10]:\n",
    "    ex_del=i.text\n",
    "    expected_Delivery.append(ex_del)\n",
    "\n",
    "availability_tags = driver.find_elements(By.XPATH,'//*[@id=\"availability\"]/span')  \n",
    "for i in availability_tags[0:10]:\n",
    "    availb=i.text\n",
    "    availability.append(availb)\n",
    "\n",
    "#Product_URL = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')  \n",
    "#for i in Product_URL[0:10]:\n",
    "   # pu=i.text\n",
    "   # Product_URL.append(pu)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "172b10e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kadence rosewood Guitar Frontier Series, Electric Acoustic Black Guitar With EQ, Die Cast Keys, Set Of Strings, Strap, Picks And Bag (Black EQ, Electric Acoustic)', 'Kadence rosewood Guitar Frontier Series, Electric Acoustic Black Guitar With EQ, Die Cast Keys, Set Of Strings, Strap, Picks And Bag (Black EQ, Electric Acoustic)']\n",
      "['4,999', '4,999']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(name_of_the_Product)\n",
    "print(price)\n",
    "print(return_Exchange)\n",
    "print(availability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6f50cd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(return_Exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8900873",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8372\\2102350267.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'product'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mname_of_the_Product\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Price'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'returnpolicy'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mreturn_Exchange\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'availability'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mavailability\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'product': name_of_the_Product,'Price':price,'returnpolicy':return_Exchange,'availability':availability })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ada0d",
   "metadata": {},
   "source": [
    "Q-3 Write a python program to access the search bar and search button on images.google.com and scrape 10\n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632acf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "def scrape_images(keyword, num_images=10):\n",
    "    # Configure the Chrome WebDriver (replace 'chromedriver_path' with the actual path to your WebDriver)\n",
    "    chromedriver_path = '/path/to/chromedriver'\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Optional: Run headless (without a visible browser window)\n",
    "    service = Service(chromedriver_path)\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    # Google Images URL\n",
    "    base_url = \"https://www.google.com/imghp\"\n",
    "    \n",
    "    # Open the Google Images website\n",
    "    driver.get(base_url)\n",
    "    \n",
    "    # Find and interact with the search bar\n",
    "    search_bar = driver.find_element_by_name(\"q\")\n",
    "    search_bar.send_keys(keyword)\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "    \n",
    "    # Scroll down the page to load more images (you may adjust this number as needed)\n",
    "    scroll_iterations = 3\n",
    "    for _ in range(scroll_iterations):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Get the page source after scrolling\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # Find image elements\n",
    "    image_elements = soup.find_all(\"img\")\n",
    "    \n",
    "    # Create a directory to save the images\n",
    "    os.makedirs(keyword, exist_ok=True)\n",
    "    \n",
    "    # Download the first 'num_images' images\n",
    "    for i, img_element in enumerate(image_elements[:num_images]):\n",
    "        img_url = img_element['src']\n",
    "        img_data = requests.get(img_url).content\n",
    "        with open(os.path.join(keyword, f\"{keyword}_{i+1}.jpg\"), 'wb') as img_file:\n",
    "            img_file.write(img_data)\n",
    "    \n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    keywords = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        scrape_images(keyword, num_images=10)\n",
    "        print(f\"Scraped 10 images for '{keyword}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826680f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de0492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85bfb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15f7e594",
   "metadata": {},
   "source": [
    "Q-4 Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand\n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the\n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265cd8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ad5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edd5d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://www.flipkart.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fa5c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box= driver.find_element(By.CLASS_NAME,\"Pke_EE       \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "382c3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d68fb6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box.send_keys('Oneplus Nord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "002df926",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'//*[@id=\"container\"]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/header/div[1]/div[2]/form/div/button')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "715ccba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add6711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_Name=[]\n",
    "smartphone_name=[]\n",
    "color=[]\n",
    "ram=[]\n",
    "storage_ROM=[]\n",
    "primary_camera=[]\n",
    "secondary_camera=[]\n",
    "display_size=[]\n",
    "battery_capacity=[]\n",
    "price=[]\n",
    "#product_url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ca18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "brand_tags = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[3]/div[1]/div[1]')\n",
    "for i in brand_tags:\n",
    "    brand=i.text\n",
    "    brand_Name.append(brand)\n",
    "\n",
    "\n",
    "smartphone_tags = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[3]/div[1]/div[1]')\n",
    "for i in smartphone_tags:\n",
    "    name=i.text\n",
    "    smartphone_name.append(name)\n",
    "    \n",
    "\n",
    "color_tags = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[3]/div[1]/div[1]')  \n",
    "for i in color_tags:\n",
    "    co_lr=i.text\n",
    "    color.append(co_lr)   \n",
    "    \n",
    "    \n",
    "ram_tags = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[3]/div[1]/div[3]/ul/li[1]')  \n",
    "for i in ram_tags:\n",
    "    ra_m=i.text\n",
    "    ram.append(ra_m)\n",
    "\n",
    "storage_ROM_tags = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[3]/div[1]/div[3]/ul/li[1]')  \n",
    "for i in storage_ROM_tags :\n",
    "    rom=i.text\n",
    "    storage_ROM.append(rom)\n",
    "\n",
    "primary_camera_tags = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[3]/div[1]/div[3]/ul/li[3]')  \n",
    "for i in primary_camera_tags:\n",
    "    p_camera=i.text\n",
    "    primary_camera.append(p_camera)\n",
    "    \n",
    "secondary_camera_tags = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[3]/div[1]/div[3]/ul/li[3]')  \n",
    "for i in secondary_camera_tags:\n",
    "    s_camera=i.text\n",
    "    secondary_camera.append(s_camera)\n",
    "\n",
    "display_size_tags = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[3]/div[1]/div[3]/ul/li[2]')  \n",
    "for i in display_size_tags:\n",
    "    d_size=i.text\n",
    "    display_size.append(d_size)\n",
    "    \n",
    "battery_capacity_tags = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[3]/div[1]/div[3]/ul/li[4]')  \n",
    "for i in battery_capacity_tags:\n",
    "    batt_c=i.text\n",
    "    battery_capacity.append(batt_c)\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH,'//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[3]/div[2]/div[1]/div[1]/div[1]')  \n",
    "for i in price_tags:\n",
    "    Price=i\n",
    "    price_tags.append(Price)\n",
    "    \n",
    "#product_url_tags = driver.find_elements(By.XPATH,'//*[@id=\"availability\"]/span')  \n",
    "#for i in availability_tags[0:10]:\n",
    "    #availb=i.text\n",
    "    #availability.append(availb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ff3767b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1532\\3240424035.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m df = pd.DataFrame({'Brand': brand_Name,'smartphone':smartphone_name,'Color':color,'RAM':ram,'ROM':storage_ROM, \n\u001b[0m\u001b[0;32m      2\u001b[0m                    \u001b[1;34m'Primarycamera'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mprimary_camera\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Secondarycamera'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msecondary_camera\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Display'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdisplay_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         'Battery':battery_capacity,'Price':price})\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand': brand_Name,'smartphone':smartphone_name,'Color':color,'RAM':ram,'ROM':storage_ROM, \n",
    "                   'Primarycamera':primary_camera,'Secondarycamera':secondary_camera,'Display':display_size,\n",
    "                        'Battery':battery_capacity,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08352312",
   "metadata": {},
   "source": [
    "Q-5Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "72469f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: New York\n",
      "Latitude: 40.6975399\n",
      "Longitude: -74.3093436\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Initialize Chrome WebDriver (ensure you have Chrome WebDriver installed and in your PATH)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open Google Maps\n",
    "driver.get(\"https://www.google.com/maps\")\n",
    "\n",
    "# Function to search for a city and extract coordinates\n",
    "def search_city_and_extract_coordinates(city_name):\n",
    "    # Find the search input field and enter the city name\n",
    "    search_input = driver.find_element(By.ID, \"searchboxinput\")\n",
    "    search_input.clear()\n",
    "    search_input.send_keys(city_name)\n",
    "    \n",
    "    # Find and click the search button\n",
    "    search_button = driver.find_element(By.ID, \"searchbox-searchbutton\")\n",
    "    search_button.click()\n",
    "    \n",
    "    # Wait for the search results to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Find and extract the coordinates from the URL\n",
    "    current_url = driver.current_url\n",
    "    coordinates = extract_coordinates_from_url(current_url)\n",
    "    \n",
    "    return coordinates\n",
    "\n",
    "# Function to extract coordinates from a Google Maps URL\n",
    "def extract_coordinates_from_url(url):\n",
    "    # Example URL format: https://www.google.com/maps/place/LATITUDE,LONGITUDE\n",
    "    parts = url.split(\"/place/New+York,+NY,+USA/@\")[1].split(\",\")\n",
    "    latitude = parts[0]\n",
    "    longitude = parts[1]\n",
    "    \n",
    "    return latitude, longitude\n",
    "\n",
    "# Input the city name you want to search for\n",
    "city_name = \"New York\"  # Replace with the desired city name\n",
    "\n",
    "# Search for the city and extract coordinates\n",
    "latitude, longitude = search_city_and_extract_coordinates(city_name)\n",
    "\n",
    "# Close the browser\n",
    "#driver.quit()\n",
    "\n",
    "# Print the extracted coordinates\n",
    "print(f\"City: {city_name}\")\n",
    "print(f\"Latitude: {latitude}\")\n",
    "print(f\"Longitude: {longitude}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b777416",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-6 Write a program to scrap all the available details of best gaming laptops from digit.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6987b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Initialize Chrome WebDriver (ensure you have Chrome WebDriver installed and in your PATH)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Digit.in page for gaming laptops\n",
    "driver.get(\"https://www.digit.in/top-products/best-gaming-laptops-40.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "21b9d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Operating_system=[]\n",
    "Display_size=[]\n",
    "Resolution=[]\n",
    "Processor=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "47bb7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name_tags = driver.find_elements(By.XPATH,'//*[@id=\"hp-omen-17-ck2008tx-13th-gen-core-i7-13700hx\"]')  \n",
    "for i in Name_tags[0:1]:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "    \n",
    "Operating_system_tags = driver.find_elements(By.XPATH,'//*[@id=\"rh_woorows_1884150590\"]/div/div[2]/div[3]/div[2]/div[1]/div/span[2]')  \n",
    "for i in Operating_system_tags[0:1]:\n",
    "    Os=i.text\n",
    "    Operating_system.append(Os)\n",
    "\n",
    "Display_size_tags = driver.find_elements(By.XPATH,'//*[@id=\"rh_woorows_1884150590\"]/div/div[2]/div[3]/div[2]/div[2]/div/span[2]')  \n",
    "for i in Display_size_tags[0:1]:\n",
    "    display=i.text\n",
    "    Display_size.append(display)\n",
    "\n",
    "\n",
    "Resolution_tags = driver.find_elements(By.XPATH,'//*[@id=\"rh_woorows_1884150590\"]/div/div[2]/div[3]/div[2]/div[3]/div/span[2]')  \n",
    "for i in Resolution_tags[0:1] :\n",
    "    resolution=i.text\n",
    "    Resolution.append(resolution)\n",
    "    \n",
    "Processor_tags = driver.find_elements(By.XPATH,'//*[@id=\"rh_woorows_1884150590\"]/div/div[2]/div[3]/div[2]/div[4]/div/span[2]')  \n",
    "for i in Processor_tags[0:1] :\n",
    "    processor=i.text\n",
    "    Processor.append(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e9aea672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>OS</th>\n",
       "      <th>Display</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>processor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Omen 17-ck2008TX 13th Gen Core i7-13700HX</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>17.3</td>\n",
       "      <td>2560 x 1440</td>\n",
       "      <td>13th Gen Intel Core i7-13700HX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           name               OS Display  \\\n",
       "0  HP Omen 17-ck2008TX 13th Gen Core i7-13700HX  Windows 11 Home    17.3   \n",
       "\n",
       "    Resolution                       processor  \n",
       "0  2560 x 1440  13th Gen Intel Core i7-13700HX  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'name':Name,'OS':Operating_system,'Display':Display_size,'Resolution':Resolution,'processor':Processor})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e09d0",
   "metadata": {},
   "source": [
    "Q-7 Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped:\n",
    "“Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2c0aec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Initialize Chrome WebDriver (ensure you have Chrome WebDriver installed and in your PATH)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open Forbes Billionaires page\n",
    "driver.get(\"https://www.forbes.com/billionaires/\")\n",
    "\n",
    "# Function to scroll to the end of the page to load all billionaire entries\n",
    "def scroll_to_end():\n",
    "    driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "    time.sleep(2)\n",
    "\n",
    "# Scroll down repeatedly until all billionaires are loaded (you may need to adjust this loop)\n",
    "while True:\n",
    "    scroll_to_end()\n",
    "    try:\n",
    "        # Look for the \"Load More\" button and click it if it exists\n",
    "        load_more_button = driver.find_element(By.XPATH, \"//button[contains(text(), 'Load More')]\")\n",
    "        load_more_button.click()\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        break  # No more \"Load More\" button found, exit the loop\n",
    "\n",
    "# Find all billionaire entries\n",
    "billionaires = driver.find_elements(By.CSS_SELECTOR, \".billionaires-list .table-row\")\n",
    "\n",
    "# Initialize empty list to store billionaire data\n",
    "billionaires_data = []\n",
    "\n",
    "# Loop through each billionaire entry and extract data\n",
    "for billionaire in billionaires:\n",
    "    rank = billionaire.find_element(By.XPATH, '//*[@id=\"bernard-arnault\"]/div[1]/div').text\n",
    "    name = billionaire.find_element(By.XPATH, '//*[@id=\"bernard-arnault\"]/div[2]/div').text\n",
    "    net_worth = billionaire.find_element(By.XPATH, '//*[@id=\"bernard-arnault\"]/div[3]/div').text\n",
    "    age = billionaire.find_element(By.XPATH, '//*[@id=\"bernard-arnault\"]/div[4]').text\n",
    "    citizenship = billionaire.find_element(By.XPATH, '//*[@id=\"bernard-arnault\"]/div[5]').text\n",
    "    source = billionaire.find_element(By.XPATH, '<div class=\"Table_dataCell__2QCve\"><span>LVMH</span><div></div></div>').text\n",
    "    industry = billionaire.find_element(By.XPATH, '//*[@id=\"bernard-arnault\"]/div[7]/div').text\n",
    "\n",
    "    billionaire_data = {\n",
    "        \"Rank\": rank,\n",
    "        \"Name\": name,\n",
    "        \"Net Worth\": net_worth,\n",
    "        \"Age\": age,\n",
    "        \"Citizenship\": citizenship,\n",
    "        \"Source\": source,\n",
    "        \"Industry\": industry,\n",
    "    }\n",
    "\n",
    "    billionaires_data.append(billionaire_data)\n",
    "    df=pd.DataFrame(billionaires_data)\n",
    "    df\n",
    "\n",
    "# Close the browser\n",
    "#driver.quit()\n",
    "\n",
    "# Print or save the scraped data as needed\n",
    "#for i, billionaire in enumerate(billionaires_data, start=1):\n",
    "    #print(f\"Billionaire {i}:\")\n",
    "    #for key, value in billionaire.items():\n",
    "        #print(f\"{key}: {value}\")\n",
    "    #print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "275380c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(billionaires_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a037438",
   "metadata": {},
   "source": [
    "Q-8 Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted\n",
    "from any YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c7a82009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>upvote</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Comment, upvote, Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# URL of the YouTube video you want to scrape comments from\n",
    "video_url = \"https://www.youtube.com/watch?v=vhwr4vc_GY0\"\n",
    "\n",
    "# Initialize Chrome WebDriver (ensure you have Chrome WebDriver installed and in your PATH)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the YouTube video page\n",
    "driver.get(video_url)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Locate the \"Show more\" button and click it to load more comments\n",
    "        show_more_button = driver.find_element(By.XPATH, \"//yt-formatted-string[contains(text(), 'Show more')]\")\n",
    "        show_more_button.click()\n",
    "        time.sleep(2)  # Wait for comments to load\n",
    "    except Exception as e:\n",
    "        break  # If no more comments to load, exit the loop\n",
    "# Initialize empty lists to store comments, upvotes, and timestamps\n",
    "comments = []\n",
    "upvotes = []\n",
    "timestamps = []\n",
    "comment_tags = driver.find_elements(By.XPATH,'//*[@id=\"content-text\"]/span')  \n",
    "for i in comment_tags[0:100]:\n",
    "    comment=i.text\n",
    "    comments.append(comment)\n",
    "upvotes_tags = driver.find_elements(By.XPATH,'//*[@id=\"vote-count-middle\"]') \n",
    "for i in upvotes_tags[0:100]:\n",
    "    upvote=i.text\n",
    "    #upvote.replace('','-')\n",
    "    upvotes.append(upvote)\n",
    "timestamps_tags = driver.find_elements(By.XPATH,'//*[@id=\"header-author\"]/yt-formatted-string/a') \n",
    "for i in timestamps_tags[0:100]:\n",
    "    timestamp=i.text\n",
    "    timestamps.append(timestamp)\n",
    "    \n",
    "df=pd.DataFrame({'Comment':comments,'upvote':upvotes,'Time':timestamps})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "efe4aadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>upvote</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Click Here to Subscribe Channel :</td>\n",
       "      <td>619</td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tara Singh ke liye aapka yeh pyaar, humare liy...</td>\n",
       "      <td>6.4K</td>\n",
       "      <td>2 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only 90's kids can understand the feeling of s...</td>\n",
       "      <td>422</td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>️</td>\n",
       "      <td>722</td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gadar 2:</td>\n",
       "      <td>14</td>\n",
       "      <td>2 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>231</td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I watched both films</td>\n",
       "      <td>5</td>\n",
       "      <td>3 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Koi Mil Gaya</td>\n",
       "      <td>355</td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and</td>\n",
       "      <td>179</td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gadar</td>\n",
       "      <td>11</td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment upvote          Time\n",
       "0                 Click Here to Subscribe Channel :     619   1 month ago\n",
       "1  Tara Singh ke liye aapka yeh pyaar, humare liy...   6.4K  2 months ago\n",
       "2  Only 90's kids can understand the feeling of s...    422   1 month ago\n",
       "3                                                  ️    722   1 month ago\n",
       "4                                           Gadar 2:     14   2 weeks ago\n",
       "5                                                       231   1 month ago\n",
       "6                              I watched both films       5    3 days ago\n",
       "7                                       Koi Mil Gaya    355   1 month ago\n",
       "8                                               and     179   1 month ago\n",
       "9                                              Gadar     11   1 month ago"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = []\n",
    "upvotes = []\n",
    "timestamps = []\n",
    "comment_tags = driver.find_elements(By.XPATH,'//*[@id=\"content-text\"]/span')  \n",
    "for i in comment_tags[0:10]:\n",
    "    comment=i.text\n",
    "    comments.append(comment)\n",
    "upvotes_tags = driver.find_elements(By.XPATH,'//*[@id=\"vote-count-middle\"]') \n",
    "for i in upvotes_tags[0:10]:\n",
    "    upvote=i.text\n",
    "    #upvote.replace('','-')\n",
    "    upvotes.append(upvote)\n",
    "timestamps_tags = driver.find_elements(By.XPATH,'//*[@id=\"header-author\"]/yt-formatted-string/a') \n",
    "for i in timestamps_tags[0:10]:\n",
    "    timestamp=i.text\n",
    "    timestamps.append(timestamp)\n",
    "    \n",
    "df=pd.DataFrame({'Comment':comments,'upvote':upvotes,'Time':timestamps})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24005215",
   "metadata": {},
   "source": [
    "Q-9 Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in\n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall\n",
    "reviews, privates from price, dorms from price, facilities and property description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1d8418eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".property-card-body .title-2\"}\n  (Session info: chrome=117.0.5938.92); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF606E07892+54818]\n\t(No symbol) [0x00007FF606D76AC2]\n\t(No symbol) [0x00007FF606C2DA3B]\n\t(No symbol) [0x00007FF606C6E4FC]\n\t(No symbol) [0x00007FF606C6E67C]\n\t(No symbol) [0x00007FF606C650FC]\n\t(No symbol) [0x00007FF606C8EAEF]\n\t(No symbol) [0x00007FF606C65036]\n\t(No symbol) [0x00007FF606C8ECC0]\n\t(No symbol) [0x00007FF606CA75A2]\n\t(No symbol) [0x00007FF606C8E883]\n\t(No symbol) [0x00007FF606C63691]\n\t(No symbol) [0x00007FF606C648D4]\n\tGetHandleVerifier [0x00007FF60716B992+3610402]\n\tGetHandleVerifier [0x00007FF6071C1860+3962352]\n\tGetHandleVerifier [0x00007FF6071B9D4F+3930847]\n\tGetHandleVerifier [0x00007FF606EA3646+693206]\n\t(No symbol) [0x00007FF606D81628]\n\t(No symbol) [0x00007FF606D7D934]\n\t(No symbol) [0x00007FF606D7DA62]\n\t(No symbol) [0x00007FF606D6E113]\n\tBaseThreadInitThunk [0x00007FFD00217344+20]\n\tRtlUserThreadStart [0x00007FFD015C26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8372\\4040736713.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# Extract hostel name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mhostel_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhostel_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\".property-card-body .title-2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# Extract distance from city centre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'[name=\"{value}\"]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_CHILD_ELEMENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".property-card-body .title-2\"}\n  (Session info: chrome=117.0.5938.92); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF606E07892+54818]\n\t(No symbol) [0x00007FF606D76AC2]\n\t(No symbol) [0x00007FF606C2DA3B]\n\t(No symbol) [0x00007FF606C6E4FC]\n\t(No symbol) [0x00007FF606C6E67C]\n\t(No symbol) [0x00007FF606C650FC]\n\t(No symbol) [0x00007FF606C8EAEF]\n\t(No symbol) [0x00007FF606C65036]\n\t(No symbol) [0x00007FF606C8ECC0]\n\t(No symbol) [0x00007FF606CA75A2]\n\t(No symbol) [0x00007FF606C8E883]\n\t(No symbol) [0x00007FF606C63691]\n\t(No symbol) [0x00007FF606C648D4]\n\tGetHandleVerifier [0x00007FF60716B992+3610402]\n\tGetHandleVerifier [0x00007FF6071C1860+3962352]\n\tGetHandleVerifier [0x00007FF6071B9D4F+3930847]\n\tGetHandleVerifier [0x00007FF606EA3646+693206]\n\t(No symbol) [0x00007FF606D81628]\n\t(No symbol) [0x00007FF606D7D934]\n\t(No symbol) [0x00007FF606D7DA62]\n\t(No symbol) [0x00007FF606D6E113]\n\tBaseThreadInitThunk [0x00007FFD00217344+20]\n\tRtlUserThreadStart [0x00007FFD015C26B1+33]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Initialize Chrome WebDriver (ensure you have Chrome WebDriver installed and in your PATH)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Define the URL for London hostels on Hostelworld\n",
    "url = \"https://www.hostelworld.com/s?q=London,%20England&country=England&city=London&type=city&id=3\"\n",
    "\n",
    "# Open the URL in the browser\n",
    "driver.get(url)\n",
    "\n",
    "# Function to scroll to the bottom of the page to load more hostels\n",
    "def scroll_to_bottom():\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# Scroll to load more hostels (you may adjust the number of scrolls based on your needs)\n",
    "for _ in range(3):\n",
    "    scroll_to_bottom()\n",
    "\n",
    "# Find all hostel elements on the page\n",
    "hostel_elements = driver.find_elements(By.CSS_SELECTOR, \".property-card\")\n",
    "\n",
    "# Initialize an empty list to store hostel data\n",
    "hostels_data = []\n",
    "\n",
    "# Loop through each hostel element and extract data\n",
    "for hostel_element in hostel_elements:\n",
    "    hostel_data = {}\n",
    "    \n",
    "    # Extract hostel name\n",
    "    hostel_data['Name'] = hostel_element.find_element(By.XPATH, \"//*[@id=\"__layout\"]/div/div[2]/div[2]/div[2]/div[1]/div/div/div/div/div[5]/div[1]/a/a/div[2]/div[1]\").text\n",
    "    \n",
    "    # Extract distance from city centre\n",
    "    hostel_data['Distance'] = hostel_element.find_element(By.XPATH, \"//*[@id=\"__layout\"]/div/div[2]/div[2]/div[2]/div[1]/div/div/div/div/div[5]/div[1]/a/a/div[2]/div[3]/span[2]\").text\n",
    "    \n",
    "    # Extract ratings and total reviews\n",
    "    ratings = hostel_element.find_element(By.XPATH, \"//*[@id=\"__layout\"]/div/div[2]/div[2]/div[2]/div[1]/div/div/div/div/div[5]/div[1]/a/a/div[2]/div[2]/div/div[1]/span[1]\").text.split()\n",
    "    hostel_data['Ratings'] = ratings[0]\n",
    "    hostel_data['Total Reviews'] = ratings[1]\n",
    "    \n",
    "    # Extract overall reviews\n",
    "    hostel_data['Overall Reviews'] = hostel_element.find_element(By.XPATH, \".reviews .rating\").text\n",
    "    \n",
    "    # Extract prices for privates and dorms\n",
    "    prices = hostel_element.find_elements(By.CSS_SELECTOR, \".prices .price\")\n",
    "    hostel_data['Privates Price'] = prices[0].text\n",
    "    hostel_data['Dorms Price'] = prices[1].text\n",
    "    \n",
    "    # Extract facilities\n",
    "    facilities = [facility.text for facility in hostel_element.find_elements(By.CSS_SELECTOR, \".facilities .label\")]\n",
    "    hostel_data['Facilities'] = ', '.join(facilities)\n",
    "    \n",
    "    # Extract property description\n",
    "    hostel_data['Property Description'] = hostel_element.find_element(By.CSS_SELECTOR, \".description\").text\n",
    "    \n",
    "    # Append the hostel data to the list\n",
    "    hostels_data.append(hostel_data)\n",
    "\n",
    "# Close the browser\n",
    "#driver.quit()\n",
    "\n",
    "# Print the scraped data\n",
    "for i, hostel in enumerate(hostels_data, start=1):\n",
    "    print(f\"Hostel {i}:\")\n",
    "    for key, value in hostel.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Save the data to a CSV file, database, or perform further processing as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07a67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2123700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c425d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f8c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
