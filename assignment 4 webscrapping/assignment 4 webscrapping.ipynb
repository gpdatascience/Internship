{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9051eff",
   "metadata": {},
   "source": [
    "Q-1 Scrape the details of most viewed videos on YouTube from Wikipedia. Url\n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417372f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0bb24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send an HTTP GET request to the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3feb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the table that contains the data for most viewed YouTube videos\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab5c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store the details\n",
    "rank_list = []\n",
    "name_list = []\n",
    "artist_list = []\n",
    "upload_date_list = []\n",
    "views_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b64bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and scrape the data from the table\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    columns = row.find_all(\"td\")\n",
    "    if len(columns) >= 5:\n",
    "        rank = columns[0].text.strip()\n",
    "        name = columns[1].text.strip()\n",
    "        artist = columns[2].text.strip()\n",
    "        upload_date = columns[3].text.strip()\n",
    "        views = columns[4].text.strip()\n",
    "\n",
    "        rank_list.append(rank)\n",
    "        name_list.append(name)\n",
    "        artist_list.append(artist)\n",
    "        upload_date_list.append(upload_date)\n",
    "        views_list.append(views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a95998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating DATAFRAME\n",
    "df=pd.DataFrame({'rank':rank_list,\n",
    "'name':name_list,\n",
    "'artist':artist_list ,\n",
    "'upload':upload_date_list ,\n",
    "'view':views_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f604da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>name</th>\n",
       "      <th>artist</th>\n",
       "      <th>upload</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>13.48</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.28</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.82</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.45</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.11</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.05</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.62</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.52</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.05</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.99</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>4.92</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.56</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.46</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.09</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.95</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.89</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.89</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.80</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.75</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Sorry\"[44]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.72</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.71</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.67</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[47]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.60</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.58</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.56</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.53</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Faded\"[51]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.53</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[52]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[53]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.48</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.48</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                                             name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[17]   \n",
       "3    4.                                  \"Bath Song\"[18]   \n",
       "4    5.                               \"Shape of You\"[19]   \n",
       "5    6.                              \"See You Again\"[22]   \n",
       "6    7.                          \"Wheels on the Bus\"[27]   \n",
       "7    8.                \"Phonics Song with Two Words\"[28]   \n",
       "8    9.                                \"Uptown Funk\"[29]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10  11.                              \"Gangnam Style\"[31]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12  13.                             \"Dame Tu Cosita\"[37]   \n",
       "13  14.                                     \"Axel F\"[38]   \n",
       "14  15.                                      \"Sugar\"[39]   \n",
       "15  16.                             \"Counting Stars\"[40]   \n",
       "16  17.                                       \"Roar\"[41]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[42]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "19  20.                                      \"Sorry\"[44]   \n",
       "20  21.                             \"Lakdi Ki Kathi\"[45]   \n",
       "21  22.                          \"Thinking Out Loud\"[46]   \n",
       "22  23.                                 \"Dark Horse\"[47]   \n",
       "23  24.          \"Humpty the train on a fruits ride\"[48]   \n",
       "24  25.                                    \"Perfect\"[49]   \n",
       "25  26.                                 \"Let Her Go\"[50]   \n",
       "26  27.                                      \"Faded\"[51]   \n",
       "27  28.                             \"Girls Like You\"[52]   \n",
       "28  29.                      \"Shree Hanuman Chalisa\"[53]   \n",
       "29  30.                                    \"Lean On\"[54]   \n",
       "\n",
       "                                               artist upload  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories  13.48   \n",
       "1                                          Luis Fonsi   8.28   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.82   \n",
       "3                          Cocomelon - Nursery Rhymes   6.45   \n",
       "4                                          Ed Sheeran   6.11   \n",
       "5                                         Wiz Khalifa   6.05   \n",
       "6                          Cocomelon - Nursery Rhymes   5.62   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs   5.52   \n",
       "8                                         Mark Ronson   5.05   \n",
       "9                                         Miroshka TV   4.99   \n",
       "10                                        officialpsy   4.92   \n",
       "11                                         Get Movies   4.56   \n",
       "12                                      Ultra Records   4.46   \n",
       "13                                         Crazy Frog   4.09   \n",
       "14                                           Maroon 5   3.95   \n",
       "15                                        OneRepublic   3.89   \n",
       "16                                         Katy Perry   3.89   \n",
       "17                         Cocomelon - Nursery Rhymes   3.80   \n",
       "18                                            Shakira   3.75   \n",
       "19                                      Justin Bieber   3.72   \n",
       "20                                       Jingle Toons   3.71   \n",
       "21                                         Ed Sheeran   3.67   \n",
       "22                                         Katy Perry   3.60   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.58   \n",
       "24                                         Ed Sheeran   3.56   \n",
       "25                                          Passenger   3.53   \n",
       "26                                        Alan Walker   3.53   \n",
       "27                                           Maroon 5   3.50   \n",
       "28                              T-Series Bhakti Sagar   3.48   \n",
       "29                               Major Lazer Official   3.48   \n",
       "\n",
       "                 view  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6        May 24, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15       May 31, 2013  \n",
       "16  September 5, 2013  \n",
       "17      June 25, 2018  \n",
       "18       June 4, 2010  \n",
       "19   October 22, 2015  \n",
       "20      June 14, 2018  \n",
       "21    October 7, 2014  \n",
       "22  February 20, 2014  \n",
       "23   January 26, 2018  \n",
       "24   November 9, 2017  \n",
       "25      July 25, 2012  \n",
       "26   December 3, 2015  \n",
       "27       May 31, 2018  \n",
       "28       May 10, 2011  \n",
       "29     March 22, 2015  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe08ef",
   "metadata": {},
   "source": [
    "Q-2 Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9989d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106d7da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9537d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d9a2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activating the browser\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3145d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the search URL\n",
    "driver.get(\"https://www.bcci.tv/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74289d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_button=driver.find_element(By.XPATH,'//button[@class=\"close-button page-close\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34f1509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f87bdd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "international_fixture=driver.find_element(By.XPATH,'//*[@id=\"pills-international-tab\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7819a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "international_fixture.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "333359fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_all_button=driver.find_element(By.XPATH,'//*[@id=\"match-1\"]/div[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "effdfbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    driver.execute_script(\"window.scrollBy(0,200)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9db6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_all_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aa2cac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing list empty\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "edab8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting content from website\n",
    "Series_tags = driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in Series_tags[0:20]:\n",
    "    series=i.text\n",
    "    Series.append(series)\n",
    "\n",
    "\n",
    "Place_tags = driver.find_elements(By.XPATH,'//*[@id=\"match-card\"]/div[2]/div[1]/span[2]')\n",
    "for i in Place_tags[0:20]:\n",
    "    place=i.text\n",
    "    Place.append(place)\n",
    "    \n",
    "\n",
    "Date_tags = driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')  \n",
    "for i in Date_tags[0:20]:\n",
    "    date=i.text\n",
    "    Date.append(date)   \n",
    "    \n",
    "    \n",
    "Time_tags = driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')  \n",
    "for i in Time_tags[0:20]:\n",
    "    time_u=i.text\n",
    "    Time.append(time_u)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2fc11b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 20, 20)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Series),len(Place),len(Date),len(Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9b173b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>13 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>13 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>15 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>15 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>17 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>17 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>20 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>20 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>22 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>22 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>23 NOVEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>24 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>24 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Thiruvananthapuram</td>\n",
       "      <td>26 NOVEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>27 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>QUADRANGULAR MENS U19 ONE DAY SERIES</td>\n",
       "      <td>Vijayawada</td>\n",
       "      <td>27 NOVEMBER, 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Guwahati</td>\n",
       "      <td>28 NOVEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Durban</td>\n",
       "      <td>10 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Tournament               Venue  \\\n",
       "0   QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "1   QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "2   QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "3   QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "4   QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "5   QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "6   QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "7   QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "8   QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "9   QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "10       AUSTRALIA TOUR OF INDIA 2023-24       Visakhapatnam   \n",
       "11  QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "12  QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "13       AUSTRALIA TOUR OF INDIA 2023-24  Thiruvananthapuram   \n",
       "14  QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "15  QUADRANGULAR MENS U19 ONE DAY SERIES          Vijayawada   \n",
       "16       AUSTRALIA TOUR OF INDIA 2023-24            Guwahati   \n",
       "17       AUSTRALIA TOUR OF INDIA 2023-24              Nagpur   \n",
       "18       AUSTRALIA TOUR OF INDIA 2023-24           Hyderabad   \n",
       "19    INDIA TOUR OF SOUTH AFRICA 2023-24              Durban   \n",
       "\n",
       "                 Date         Time  \n",
       "0   13 NOVEMBER, 2023  9:00 AM IST  \n",
       "1   13 NOVEMBER, 2023  9:00 AM IST  \n",
       "2   15 NOVEMBER, 2023  9:00 AM IST  \n",
       "3   15 NOVEMBER, 2023  9:00 AM IST  \n",
       "4   17 NOVEMBER, 2023  9:00 AM IST  \n",
       "5   17 NOVEMBER, 2023  9:00 AM IST  \n",
       "6   20 NOVEMBER, 2023  9:00 AM IST  \n",
       "7   20 NOVEMBER, 2023  9:00 AM IST  \n",
       "8   22 NOVEMBER, 2023  9:00 AM IST  \n",
       "9   22 NOVEMBER, 2023  9:00 AM IST  \n",
       "10  23 NOVEMBER, 2023  7:00 PM IST  \n",
       "11  24 NOVEMBER, 2023  9:00 AM IST  \n",
       "12  24 NOVEMBER, 2023  9:00 AM IST  \n",
       "13  26 NOVEMBER, 2023  7:00 PM IST  \n",
       "14  27 NOVEMBER, 2023  9:00 AM IST  \n",
       "15  27 NOVEMBER, 2023  9:00 AM IST  \n",
       "16  28 NOVEMBER, 2023  7:00 PM IST  \n",
       "17   1 DECEMBER, 2023  7:00 PM IST  \n",
       "18   3 DECEMBER, 2023  7:00 PM IST  \n",
       "19  10 DECEMBER, 2023  9:30 PM IST  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for scrapped data\n",
    "Cricket=pd.DataFrame({'Tournament':Series,'Venue':Place,'Date':Date,'Time':Time})\n",
    "Cricket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc19c87d",
   "metadata": {},
   "source": [
    "Q-3 Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b44d6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f32fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the search URL\n",
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "092d403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty lists\n",
    "Rank =[]\n",
    "State =[]\n",
    "GDSP_19_20=[]\n",
    "GDSP_18_19 =[]\n",
    "Share =[]\n",
    "GDP =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "269e3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Clicking on India under ecomony section\n",
    "India=driver.find_element(By.XPATH,'//div[@class=\"dropdown\"][2]/div/a[3]')\n",
    "try:\n",
    "    India.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(India.get_attribute('href'))\n",
    "    \n",
    "time.sleep(2)\n",
    "\n",
    "# Clicking Indian State GDP\n",
    "state = driver.find_element(By.XPATH,'//ul[@style=\"list-style-type:none;margin-left:20px;\"]/li[1]/a')\n",
    "try:\n",
    "    state.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(state.get_attribute('href'))\n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b858a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank via Xpath\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "# Extracting state name via Xpath\n",
    "try:\n",
    "    state=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "    for i in state:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append('NA')\n",
    "    \n",
    "# Extracting GDSP 19-20 via Xpath\n",
    "try:\n",
    "    gdsp_19_20=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "    for i in gdsp_19_20:\n",
    "        GDSP_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDSP_19_20.append('NA')\n",
    "    \n",
    "# Extracting GDSP 18-19 via Xpath\n",
    "try:\n",
    "    gdsp_18_19=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gdsp_18_19:\n",
    "        GDSP_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDSP_18_19.append('NA')\n",
    "    \n",
    "# Extracting share in billons via Xpath\n",
    "try:\n",
    "    share=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in share:\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append('NA')\n",
    "\n",
    "# Extracting GDP via Xpath\n",
    "try:\n",
    "    gdp=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in gdp:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c28c9b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GDSP 19-20</th>\n",
       "      <th>GDSP 18-19</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP (in Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GDSP 19-20 GDSP 18-19   Share  \\\n",
       "0     1                Maharashtra          -  2,632,792  13.94%   \n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208   8.63%   \n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764   8.39%   \n",
       "3     4                    Gujarat          -  1,502,899   7.96%   \n",
       "4     5                  Karnataka  1,631,977  1,493,127   7.91%   \n",
       "5     6                West Bengal  1,253,832  1,089,898   5.77%   \n",
       "6     7                  Rajasthan  1,020,989    942,586   4.99%   \n",
       "7     8             Andhra Pradesh    972,782    862,957   4.57%   \n",
       "8     9                  Telangana    969,604    861,031   4.56%   \n",
       "9    10             Madhya Pradesh    906,672    809,592   4.29%   \n",
       "10   11                     Kerala          -    781,653   4.14%   \n",
       "11   12                      Delhi    856,112    774,870   4.10%   \n",
       "12   13                    Haryana    831,610    734,163   3.89%   \n",
       "13   14                      Bihar    611,804    530,363   2.81%   \n",
       "14   15                     Punjab    574,760    526,376   2.79%   \n",
       "15   16                     Odisha    521,275    487,805   2.58%   \n",
       "16   17                      Assam          -    315,881   1.67%   \n",
       "17   18               Chhattisgarh    329,180    304,063   1.61%   \n",
       "18   19                  Jharkhand    328,598    297,204   1.57%   \n",
       "19   20                Uttarakhand          -    245,895   1.30%   \n",
       "20   21            Jammu & Kashmir          -    155,956   0.83%   \n",
       "21   22           Himachal Pradesh    165,472    153,845   0.81%   \n",
       "22   23                        Goa     80,449     73,170   0.39%   \n",
       "23   24                    Tripura     55,984     49,845   0.26%   \n",
       "24   25                 Chandigarh          -     42,114   0.22%   \n",
       "25   26                 Puducherry     38,253     34,433   0.18%   \n",
       "26   27                  Meghalaya     36,572     33,481   0.18%   \n",
       "27   28                     Sikkim     32,496     28,723   0.15%   \n",
       "28   29                    Manipur     31,790     27,870   0.15%   \n",
       "29   30                   Nagaland          -     27,283   0.14%   \n",
       "30   31          Arunachal Pradesh          -     24,603   0.13%   \n",
       "31   32                    Mizoram     26,503     22,287   0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -          -       -   \n",
       "\n",
       "   GDP (in Billions)  \n",
       "0            399.921  \n",
       "1            247.629  \n",
       "2            240.726  \n",
       "3            228.290  \n",
       "4            226.806  \n",
       "5            165.556  \n",
       "6            143.179  \n",
       "7            131.083  \n",
       "8            130.791  \n",
       "9            122.977  \n",
       "10           118.733  \n",
       "11           117.703  \n",
       "12           111.519  \n",
       "13            80.562  \n",
       "14            79.957  \n",
       "15            74.098  \n",
       "16            47.982  \n",
       "17            46.187  \n",
       "18            45.145  \n",
       "19            37.351  \n",
       "20            23.690  \n",
       "21            23.369  \n",
       "22            11.115  \n",
       "23             7.571  \n",
       "24             6.397  \n",
       "25             5.230  \n",
       "26             5.086  \n",
       "27             4.363  \n",
       "28             4.233  \n",
       "29             4.144  \n",
       "30             3.737  \n",
       "31             3.385  \n",
       "32                 -  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for scrap data\n",
    "Statewise_GDP=pd.DataFrame({'Rank':Rank,'State':State,'GDSP 19-20':GDSP_19_20,'GDSP 18-19':GDSP_18_19,\n",
    "                            'Share':Share,'GDP (in Billions)':GDP})\n",
    "\n",
    "Statewise_GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d3785f",
   "metadata": {},
   "source": [
    "Q-4 Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08077cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ff0d4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bcc97ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7457ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening github webpage\n",
    "url='https://github.com/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "213574ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_down=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]')\n",
    "drop_down.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5ffc9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_source=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "open_source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "780616e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clicking on trending option\n",
    "trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "try:\n",
    "    trending.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c2f3f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize empty list\n",
    "Title=[]\n",
    "Description=[]\n",
    "Count=[]\n",
    "Language=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d601ea2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8d9dc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the data\n",
    "Title_tags=driver.find_elements(By.XPATH,'//span[@class=\"text-normal\"]')\n",
    "for i in  Title_tags:\n",
    "    title=i.text\n",
    "    Title.append(title)\n",
    "Description_tags=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in  Description_tags:\n",
    "    desctiption=i.text\n",
    "    Description.append(desctiption)\n",
    "Count_tags=driver.find_elements(By.XPATH,'//a[@class=\"Link Link--muted d-inline-block mr-3\"]')\n",
    "for i in  Count_tags[1::2]:\n",
    "    count=i.text\n",
    "    Count.append(count)\n",
    "Language_tags=driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]')\n",
    "for i in  Language_tags:\n",
    "    language=i.text\n",
    "    Language.append(language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6567a4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 23, 25, 22)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Title),len(Description),len(Count),len(Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9cd1215c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ByteByteGoHq /</td>\n",
       "      <td>Explain complex systems using visuals and simp...</td>\n",
       "      <td>1,686</td>\n",
       "      <td>Dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>localsend /</td>\n",
       "      <td>An open source cross-platform alternative to A...</td>\n",
       "      <td>886</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alex313031 /</td>\n",
       "      <td>Chromium fork named after radioactive element ...</td>\n",
       "      <td>68</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenBMB /</td>\n",
       "      <td>An Autonomous LLM Agent for Complex Task Solving</td>\n",
       "      <td>174</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lyswhut /</td>\n",
       "      <td>一个基于 electron 的音乐软件</td>\n",
       "      <td>5,045</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NVIDIA /</td>\n",
       "      <td>TensorRT Extension for Stable Diffusion Web UI</td>\n",
       "      <td>30</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>epicweb-dev /</td>\n",
       "      <td>Learn the foundational skills of building full...</td>\n",
       "      <td>54</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TheRealJoelmatic /</td>\n",
       "      <td>Removes The \"Ad blocker are not allowed on You...</td>\n",
       "      <td>67</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cloudcommunity /</td>\n",
       "      <td>A curated list of free courses &amp; certifications.</td>\n",
       "      <td>886</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wagtail /</td>\n",
       "      <td>A Django content management system focused on ...</td>\n",
       "      <td>3,444</td>\n",
       "      <td>CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cpacker /</td>\n",
       "      <td>Teaching LLMs memory management for unbounded ...</td>\n",
       "      <td>291</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0x48piraj /</td>\n",
       "      <td>Friendly Adblock for YouTube: A fast, lightwei...</td>\n",
       "      <td>24</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>devfullcycle /</td>\n",
       "      <td>A sample app for the Retrieval-Augmented Gener...</td>\n",
       "      <td>56</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Azure-Samples /</td>\n",
       "      <td>OpenAgents: An Open Platform for Language Agen...</td>\n",
       "      <td>2,243</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xlang-ai /</td>\n",
       "      <td>Node.js JavaScript runtime ✨🐢🚀✨</td>\n",
       "      <td>33</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ProfSynapse /</td>\n",
       "      <td>Cockpit is a web-based graphical interface for...</td>\n",
       "      <td>230</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nodejs /</td>\n",
       "      <td>A powerful cross-platform UI toolkit for build...</td>\n",
       "      <td>27,395</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cockpit-project /</td>\n",
       "      <td>🚀 Strapi is the leading open-source headless C...</td>\n",
       "      <td>1,054</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ionic-team /</td>\n",
       "      <td>C# application with primary purpose of farming...</td>\n",
       "      <td>13,689</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>strapi /</td>\n",
       "      <td>Latent Consistency Models: Synthesizing High-R...</td>\n",
       "      <td>7,142</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Title                                        Description  \\\n",
       "0       ByteByteGoHq /  Explain complex systems using visuals and simp...   \n",
       "1          localsend /  An open source cross-platform alternative to A...   \n",
       "2         Alex313031 /  Chromium fork named after radioactive element ...   \n",
       "3            OpenBMB /   An Autonomous LLM Agent for Complex Task Solving   \n",
       "4            lyswhut /                                一个基于 electron 的音乐软件   \n",
       "5             NVIDIA /     TensorRT Extension for Stable Diffusion Web UI   \n",
       "6        epicweb-dev /  Learn the foundational skills of building full...   \n",
       "7   TheRealJoelmatic /  Removes The \"Ad blocker are not allowed on You...   \n",
       "8     cloudcommunity /   A curated list of free courses & certifications.   \n",
       "9            wagtail /  A Django content management system focused on ...   \n",
       "10           cpacker /  Teaching LLMs memory management for unbounded ...   \n",
       "11         0x48piraj /  Friendly Adblock for YouTube: A fast, lightwei...   \n",
       "12      devfullcycle /  A sample app for the Retrieval-Augmented Gener...   \n",
       "13     Azure-Samples /  OpenAgents: An Open Platform for Language Agen...   \n",
       "14          xlang-ai /                    Node.js JavaScript runtime ✨🐢🚀✨   \n",
       "15       ProfSynapse /  Cockpit is a web-based graphical interface for...   \n",
       "16            nodejs /  A powerful cross-platform UI toolkit for build...   \n",
       "17   cockpit-project /  🚀 Strapi is the leading open-source headless C...   \n",
       "18        ionic-team /  C# application with primary purpose of farming...   \n",
       "19            strapi /  Latent Consistency Models: Synthesizing High-R...   \n",
       "\n",
       "   Contributors_count language_used  \n",
       "0               1,686          Dart  \n",
       "1                 886           C++  \n",
       "2                  68    TypeScript  \n",
       "3                 174    TypeScript  \n",
       "4               5,045        Python  \n",
       "5                  30    TypeScript  \n",
       "6                  54    JavaScript  \n",
       "7                  67        Python  \n",
       "8                 886        Python  \n",
       "9               3,444           CSS  \n",
       "10                291    TypeScript  \n",
       "11                 24        Python  \n",
       "12                 56        Python  \n",
       "13              2,243    JavaScript  \n",
       "14                 33             C  \n",
       "15                230    TypeScript  \n",
       "16             27,395    JavaScript  \n",
       "17              1,054            C#  \n",
       "18             13,689        Python  \n",
       "19              7,142        Python  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "Github=pd.DataFrame({'Title':Title[0:20],'Description':Description[0:20],\n",
    "                'Contributors_count':Count[0:20],'language_used':Language[0:20]})\n",
    "\n",
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ea25f",
   "metadata": {},
   "source": [
    "Q-5 Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "28bad7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2e4890d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ddd092ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the search URL\n",
    "driver.get(\"https:/www.billboard.com/ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "62e8cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_button=driver.find_element(By.XPATH,'//*[@id=\"mega-menu-item-charts\"]/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "06470f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0a9e8e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_hundred=driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/main/div[2]/div[3]/div/div/div[2]/div/div[1]/a/span/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b82b779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_hundred.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f737180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e84164c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Song =[]\n",
    "Artist =[]\n",
    "Last_Week_rank=[]\n",
    "Peak_rank =[]\n",
    "Weeks =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2f42d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(550):\n",
    "    driver.execute_script(\"window.scrollBy(0,650)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a8043ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Song Name\n",
    "Song_tags=driver.find_elements(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "for i in  Song_tags:\n",
    "    song=i.text\n",
    "    Song.append(song)\n",
    "\n",
    "    \n",
    "# Scraping Song Artist Name\n",
    "Artist_tags=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "for i in  Artist_tags[::2]:\n",
    "    artist=i.text\n",
    "    Artist.append(artist)\n",
    "    \n",
    "# Scraping Song last week rank\n",
    "Last_Week_rank_tags=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]')\n",
    "for i in  Last_Week_rank_tags[::2]:\n",
    "    last_week=i.text\n",
    "    Last_Week_rank.append(last_week)\n",
    "\n",
    "# Scraping Song peak rank\n",
    "Peak_rank_tags=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light lrv-u-flex-grow-1\"]')\n",
    "for i in  Peak_rank_tags:\n",
    "    peak_rank=i.text\n",
    "    Peak_rank.append(peak_rank)\n",
    "\n",
    "# Scraping Weeks\n",
    "Weeks_tags=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]')\n",
    "for i in  Weeks_tags[::2]:\n",
    "    week=i.text\n",
    "    Weeks.append(week)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "26a3da57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 50, 297, 200, 297)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Song),len(Artist),len(Last_Week_rank),len(Peak_rank),len(Weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "78261a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBillboard Hot 100 Songs :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Weeks_on_chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDGAF</td>\n",
       "      <td>Drake Featuring Yeat</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Drake Featuring SZA</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calling For You</td>\n",
       "      <td>Drake</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Slime You Out</td>\n",
       "      <td>Drake</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Snooze</td>\n",
       "      <td>Drake Featuring Bad Bunny</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Daylight</td>\n",
       "      <td>Zach Bryan Featuring Kacey Musgraves</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Drake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fear Of Heights</td>\n",
       "      <td>Drake</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rich Baby Daddy</td>\n",
       "      <td>Drake</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gently</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Drake Featuring PARTYNEXTDOOR</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I Remember Everything</td>\n",
       "      <td>Drake Featuring Chief Keef</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Amen</td>\n",
       "      <td>Dua Lipa</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7969 Santa</td>\n",
       "      <td>Tate McRae</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8am In Charlotte</td>\n",
       "      <td>Drake</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What Would Pluto Do</td>\n",
       "      <td>Jelly Roll</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Drake</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bahamas Promises</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tried Our Best</td>\n",
       "      <td>Lainey Wilson</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Vampire</td>\n",
       "      <td>Drake</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Fukumean</td>\n",
       "      <td>SZA</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Members Only</td>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Thinkin' Bout Me</td>\n",
       "      <td>Usher, Summer Walker &amp; 21 Savage</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>All The Parties</td>\n",
       "      <td>Metro Boomin, The Weeknd &amp; 21 Savage</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Drew A Picasso</td>\n",
       "      <td>David Kushner</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dance The Night</td>\n",
       "      <td>Mitski</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Another Late Night</td>\n",
       "      <td>Travis Scott</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Greedy</td>\n",
       "      <td>Jung Kook &amp; Jack Harlow</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Barbie World</td>\n",
       "      <td>Karol G &amp; Peso Pluma</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Away From Home</td>\n",
       "      <td>Selena Gomez</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Peso Pluma, Gabito Ballesteros &amp; Junior H</td>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Need A Favor</td>\n",
       "      <td>Paul Russell</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Religiously</td>\n",
       "      <td>Rod Wave</td>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BBL Love Interlude</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Polar Opposites</td>\n",
       "      <td>Zach Bryan Featuring The War And Treaty</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Used To Be Young</td>\n",
       "      <td>Noah Kahan</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bad Idea Right?</td>\n",
       "      <td>Noah Kahan With Kacey Musgraves</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Watermelon Moonshine</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Maluma &amp; Carin Leon</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Screw The World Interlude</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Dial Drunk</td>\n",
       "      <td>Sexyy Red</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>Grupo Frontera &amp; Grupo Firme</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Karol G</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>What Was I Made For?</td>\n",
       "      <td>Dylan Scott</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>What It Is (Block Boy)</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Good Good</td>\n",
       "      <td>Tim McGraw</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Wild Ones</td>\n",
       "      <td>Russell Dickerson</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Creepin'</td>\n",
       "      <td>Travis Scott Featuring SZA &amp; Future</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>White Horse</td>\n",
       "      <td>Dustin Lynch</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Song_Name                                Artist_Name  \\\n",
       "0                       IDGAF                       Drake Featuring Yeat   \n",
       "1              Virginia Beach                                   Doja Cat   \n",
       "2          Paint The Town Red                        Drake Featuring SZA   \n",
       "3             Calling For You                                      Drake   \n",
       "4               Slime You Out                                      Drake   \n",
       "5                      Snooze                  Drake Featuring Bad Bunny   \n",
       "6                    Daylight       Zach Bryan Featuring Kacey Musgraves   \n",
       "7                Cruel Summer                                      Drake   \n",
       "8             Fear Of Heights                                      Drake   \n",
       "9             Rich Baby Daddy                                      Drake   \n",
       "10                     Gently                             Olivia Rodrigo   \n",
       "11                   Fast Car              Drake Featuring PARTYNEXTDOOR   \n",
       "12      I Remember Everything                 Drake Featuring Chief Keef   \n",
       "13                       Amen                                   Dua Lipa   \n",
       "14                 7969 Santa                                 Tate McRae   \n",
       "15           8am In Charlotte                                      Drake   \n",
       "16        What Would Pluto Do                                 Jelly Roll   \n",
       "17                 Last Night                                      Drake   \n",
       "18           Bahamas Promises                                Miley Cyrus   \n",
       "19             Tried Our Best                              Lainey Wilson   \n",
       "20                    Vampire                                      Drake   \n",
       "21                   Fukumean                                        SZA   \n",
       "22               Members Only                              Billie Eilish   \n",
       "23           Thinkin' Bout Me           Usher, Summer Walker & 21 Savage   \n",
       "24            All The Parties       Metro Boomin, The Weeknd & 21 Savage   \n",
       "25             Drew A Picasso                              David Kushner   \n",
       "26            Dance The Night                                     Mitski   \n",
       "27         Another Late Night                               Travis Scott   \n",
       "28                     Greedy                    Jung Kook & Jack Harlow   \n",
       "29               Barbie World                       Karol G & Peso Pluma   \n",
       "30             Away From Home                               Selena Gomez   \n",
       "31                    Flowers  Peso Pluma, Gabito Ballesteros & Junior H   \n",
       "32               Need A Favor                               Paul Russell   \n",
       "33                Religiously                                   Rod Wave   \n",
       "34         BBL Love Interlude                                  Bad Bunny   \n",
       "35            Polar Opposites    Zach Bryan Featuring The War And Treaty   \n",
       "36           Used To Be Young                                 Noah Kahan   \n",
       "37            Bad Idea Right?            Noah Kahan With Kacey Musgraves   \n",
       "38       Watermelon Moonshine                              Morgan Wallen   \n",
       "39                  Anti-Hero                        Maluma & Carin Leon   \n",
       "40  Screw The World Interlude                                     *NSYNC   \n",
       "41                 Dial Drunk                                  Sexyy Red   \n",
       "42                  Kill Bill               Grupo Frontera & Grupo Firme   \n",
       "43                All My Life                                    Karol G   \n",
       "44       What Was I Made For?                                Dylan Scott   \n",
       "45     What It Is (Block Boy)                                 Zach Bryan   \n",
       "46                  Good Good                                 Tim McGraw   \n",
       "47                  Wild Ones                          Russell Dickerson   \n",
       "48                   Creepin'        Travis Scott Featuring SZA & Future   \n",
       "49                White Horse                               Dustin Lynch   \n",
       "\n",
       "   Last_week_rank Peak Weeks_on_chart  \n",
       "0                                      \n",
       "1                    1                 \n",
       "2               2                   2  \n",
       "3                    2                 \n",
       "4                                      \n",
       "5               3    3              3  \n",
       "6                                      \n",
       "7                    1                 \n",
       "8               1                   1  \n",
       "9                    5                 \n",
       "10                                     \n",
       "11              5    1              5  \n",
       "12                                     \n",
       "13                   2                 \n",
       "14              1                   1  \n",
       "15                   8                 \n",
       "16                                     \n",
       "17              2    3              2  \n",
       "18                                     \n",
       "19                  10                 \n",
       "20              8                   8  \n",
       "21                  11                 \n",
       "22                                     \n",
       "23              3   12              3  \n",
       "24                                     \n",
       "25                   2                 \n",
       "26             10                  10  \n",
       "27                   1                 \n",
       "28                                     \n",
       "29             11   15             11  \n",
       "30                                     \n",
       "31                  16                 \n",
       "32             12                  12  \n",
       "33                  17                 \n",
       "34                                     \n",
       "35              2   18              2  \n",
       "36                                     \n",
       "37                   1                 \n",
       "38              1                   1  \n",
       "39                  20                 \n",
       "40                                     \n",
       "41             15   21             15  \n",
       "42                                     \n",
       "43                   1                 \n",
       "44             16                  16  \n",
       "45                   4                 \n",
       "46                                     \n",
       "47             17   24             17  \n",
       "48                                     \n",
       "49                   9                 "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Billboard=pd.DataFrame({'Song_Name':Song[0:50],\n",
    "                'Artist_Name':Artist[0:50],\n",
    "                'Last_week_rank':Last_Week_rank[0:50],\n",
    "                'Peak':Peak_rank[0:50],\n",
    "                'Weeks_on_chart':Weeks[0:50]})\n",
    "print('\\033[1m'+'Billboard Hot 100 Songs :'+'\\033[0m')\n",
    "Billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-6 Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c05ceba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628af572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening Wikipedia webpage\n",
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f382b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty Lists\n",
    "Book =[]\n",
    "Author =[]\n",
    "Volumes_sold =[]\n",
    "Publisher =[]\n",
    "Genre =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84654bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book name\n",
    "try:\n",
    "    book=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in book:\n",
    "        Book.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Book.append('NA')\n",
    "    \n",
    "# Scraping Book author's via Xpath\n",
    "try:\n",
    "    author=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in author:\n",
    "        Author.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Author.append('NA')\n",
    "    \n",
    "# Scraping Volumes sold via Xpath\n",
    "try:\n",
    "    sold=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in sold:\n",
    "        Volumes_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Volumes_sold.append('NA')\n",
    "    \n",
    "# Scraping publisher via xPath\n",
    "try:\n",
    "    publisher=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publisher:\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Publisher.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6defc4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest Selling Books of All Time List by The Guardian  :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book Title       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "Top_Books=pd.DataFrame({\"Book Title\":Book,\n",
    "                \"Author Name\":Author,\n",
    "                'Volumes sold':Volumes_sold,\n",
    "                'Publisher':Publisher,\n",
    "                'Genre':Genre})\n",
    "print('\\033[1m'+'Best Selling Books of All Time List by The Guardian  :'+'\\033[0m')\n",
    "Top_Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-7 Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16583a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0815cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# connecting to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening Wikipedia webpage\n",
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b51462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Name =[]\n",
    "Year_Span=[]\n",
    "Genre =[]\n",
    "Run_Time =[]\n",
    "Ratings =[]\n",
    "Votes =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "449050bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Name via Xpath\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('NA')\n",
    "\n",
    "# Scraping Year span via Xpath\n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in year:\n",
    "        Year_Span.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year_Span.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')\n",
    "    \n",
    "# Scraping RunTime via Xpath\n",
    "try:\n",
    "    runtime=driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "    for i in runtime:\n",
    "        Run_Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Run_Time.append('NA')\n",
    "\n",
    "# Scraping Ratings via Xpath\n",
    "try:\n",
    "    ratings=driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "    for i in ratings:\n",
    "        Ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Ratings.append('NA')\n",
    "\n",
    "# Scraping Votes via Xpath\n",
    "try:\n",
    "    votes=driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "    for i in votes:\n",
    "        Votes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Votes.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24b4bdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 100, 100, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Name),len(Year_Span),len(Genre),len(Run_Time),len(Ratings),len(Votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bb99f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,212,663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,282,640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,049,882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>308,505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>267,469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65,010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>211,829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44,085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>269,223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,212,663  \n",
       "1    51 min     8.7  1,282,640  \n",
       "2    44 min     8.1  1,049,882  \n",
       "3    60 min     7.5    308,505  \n",
       "4    43 min     7.6    267,469  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,940  \n",
       "96   50 min     7.8     65,010  \n",
       "97   42 min     8.1    211,829  \n",
       "98   45 min       7     44,085  \n",
       "99  572 min     8.6    269,223  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "IMDB_TV=pd.DataFrame({\"Name\":Name,\n",
    "                \"Year Span\":Year_Span,\n",
    "                \"Genre\":Genre,\n",
    "                \"Run Time\":Run_Time,\n",
    "                \"Ratings\":Ratings,\n",
    "                \"Votes\":Votes})\n",
    "\n",
    "IMDB_TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-8 Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You\n",
    "have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "566bfaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d508e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to webdriver\n",
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening Wikipedia webpage\n",
    "url='https://archive.ics.uci.edu/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "30d6f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_button=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]\")\n",
    "dataset_button.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fc0d44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping repositories URL\n",
    "product_URL= []\n",
    "link=driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in link:\n",
    "    product_URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e1b92fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://archive.ics.uci.edu/dataset/53/iris', 'https://archive.ics.uci.edu/dataset/45/heart+disease', 'https://archive.ics.uci.edu/dataset/2/adult', 'https://archive.ics.uci.edu/dataset/109/wine', 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'https://archive.ics.uci.edu/dataset/34/diabetes', 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset', 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik', 'https://archive.ics.uci.edu/dataset/186/wine+quality']\n"
     ]
    }
   ],
   "source": [
    "print(product_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a9cf0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "Dataset =[]\n",
    "Data_Type =[]\n",
    "Task =[]\n",
    "Attribute_Type =[]\n",
    "No_of_Instances =[]\n",
    "No_of_Attribute =[]\n",
    "Year =[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e6194e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping DataSet Name via Xpath\n",
    "from tqdm import tqdm\n",
    "for URL in product_URL:\n",
    "    driver.get(URL)\n",
    "    time.sleep(20)\n",
    "try:\n",
    "    dataset=driver.find_element(By.XPATH,'//h1[@class=\"text-3xl font-semibold text-primary-content\"]')\n",
    "    Dataset.append(dataset.text)\n",
    "    time.sleep(5)\n",
    "except NoSuchElementException:\n",
    "    Dataset.append('NA')\n",
    "    \n",
    "# Scraping Data Type via Xpath\n",
    "try:\n",
    "    Type=driver.find_element(By.XPATH,'//p[@class=\"text-md\"]')\n",
    "    Data_Type.append(Type.text)\n",
    "    time.sleep(5)\n",
    "except NoSuchElementException:\n",
    "    Data_Type.append('NA')\n",
    "    \n",
    "# Scraping Task via Xpath\n",
    "try:\n",
    "    task=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[3]/p')\n",
    "    Task.append(task.text)\n",
    "    time.sleep(5)        \n",
    "except NoSuchElementException:\n",
    "    Task.append('NA')\n",
    "    \n",
    "# Scraping Attribute_Type via Xpath\n",
    "try:\n",
    "    attribute_Type=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[4]/p')\n",
    "    Attribute_Type.append(attribute_Type.text)\n",
    "    time.sleep(5)  \n",
    "except NoSuchElementException:\n",
    "    Attribute_Type.append('NA')\n",
    "    \n",
    "# Scraping No_of_Instances via Xpath\n",
    "try:\n",
    "    no_of_Instances=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[5]/p')\n",
    "    No_of_Instances.append(no_of_Instances.text)\n",
    "    time.sleep(5)\n",
    "except NoSuchElementException:\n",
    "    No_of_Instances.append('NA')\n",
    "\n",
    "# Scraping No_of_Attribute via Xpath\n",
    "try:\n",
    "    no_of_Attribute=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[6]/p')\n",
    "    No_of_Attribute.append(no_of_Attribute.text)\n",
    "    time.sleep(5)\n",
    "except NoSuchElementException:\n",
    "    No_of_Attribute.append('NA')\n",
    "    \n",
    "# Scraping Year via Xpath\n",
    "try:\n",
    "    year=driver.find_element(By.XPATH,'//h2[@class=\"text-sm text-primary-content\"]')\n",
    "    Year.append(year.text)\n",
    "    time.sleep(5)\n",
    "except NoSuchElementException:\n",
    "    Year.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7700ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_all_button= driver.find_element(By.XPATH,'//span[@class=\"swap-on text-primary-content\"]')\n",
    "expand_all_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c71b9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Data for different Attributes-\n",
    "\n",
    "dataset_tags = driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in dataset_tags:\n",
    "    dataset=i.text\n",
    "    Dataset.append(dataset)\n",
    "\n",
    "\n",
    "datatype_tags = driver.find_elements(By.XPATH,'//p[@class=\"truncate\"]')\n",
    "for i in datatype_tags[0:10]:\n",
    "    datatype=i.text\n",
    "    Data_Type.append(datatype)\n",
    "    \n",
    "\n",
    "Task_tags = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[3]/p')  \n",
    "for i in Task_tags[0:10]:\n",
    "    tsk=i.text\n",
    "    Task.append(tsk)   \n",
    "    \n",
    "    \n",
    "Attribute_Type_tags = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[4]/p')  \n",
    "for i in Attribute_Type_tags[0:10]:\n",
    "    attribute=i.text\n",
    "    Attribute_Type.append(attribute)\n",
    "\n",
    "No_of_Instances_tags = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[5]/p')  \n",
    "for i in No_of_Instances_tags[0:10]:\n",
    "    number=i.text\n",
    "    No_of_Instances.append(number)\n",
    "\n",
    "No_of_Attribute_tags = driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[6]/p')  \n",
    "for i in No_of_Attribute_tags[0:10]:\n",
    "    attribute_nu=i.text\n",
    "    No_of_Attribute.append(attribute_nu)\n",
    "\n",
    "Year_tags = driver.find_elements(By.XPATH,'//h2[@class=\"text-sm text-primary-content\"]')  \n",
    "for i in Year_tags[0:10]:\n",
    "    year=i.text\n",
    "    Year.append(year)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "11a85532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 11, 1, 1, 1, 1)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dataset),len(Data_Type),len(Task),len(Attribute_Type),len(No_of_Instances),len(Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f7776381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.', '4 databases: Cleveland, Hungary, Switzerland, and the VA Long Beach', 'Predict whether income exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset.', 'Using chemical analysis to determine the origin of wines', 'Diagnostic Wisconsin Breast Cancer Database.', \"This diabetes dataset is from AIM '94\", 'Images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. A total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.', 'Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.', \"A total of 3810 rice grain's images were taken for the two species, processed and feature inferences were made. 7 morphological features were obtained for each grain of rice.\", 'Two datasets are included, related to red and white vinho verde wine samples, from the north of Portugal. The goal is to model wine quality based on physicochemical tests (see [Cortez et al., 2009], http://www3.dsi.uminho.pt/pcortez/wine/).', 'Multivariate']\n"
     ]
    }
   ],
   "source": [
    "print(Data_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9d2aa7f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_324\\3669722525.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creating Data Frame for UCI Dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m UCI_Dataset=pd.DataFrame({'DataSet Title':Dataset[0:3],\n\u001b[0m\u001b[0;32m      3\u001b[0m                 \u001b[1;34m'Data Type'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mData_Type\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[1;34m'Task'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mTask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[1;34m'Attribute Type'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mAttribute_Type\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Creating Data Frame for UCI Dataset\n",
    "UCI_Dataset=pd.DataFrame({'DataSet Title':Dataset[0:3],\n",
    "                'Data Type':Data_Type[0:3],\n",
    "                'Task':Task[0:3],\n",
    "                'Attribute Type':Attribute_Type[0:3],\n",
    "                'No of Instances':No_of_Instances[0:3],\n",
    "                'No of Attribute':No_of_Attribute[0:3],\n",
    "                'Year':Year[0:3]})\n",
    "print('\\033[1m'+' UCI Machine Learning Dataset:'+'\\033[0m')\n",
    "UCI_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2c780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
